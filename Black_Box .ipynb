{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Black Box.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpV0s9bFH-H4",
        "outputId": "d51f7b54-9a4a-43f7-ff90-8cbdee7ef516"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "id": "TpV0s9bFH-H4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUumZKOSJTuP"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/\""
      ],
      "id": "OUumZKOSJTuP",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sufficient-middle"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import hstack\n",
        "import scipy\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import time\n",
        "t=1"
      ],
      "id": "sufficient-middle",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "collectible-beverage"
      },
      "source": [
        "X = scipy.sparse.load_npz(path+'data/countvec/train_steps_vec.npz').toarray().astype(np.int32)\n",
        "X_n = pd.read_csv(path+'data/recipe_train.csv').loc[:, ['n_steps', 'n_ingredients']].values\n",
        "X = np.hstack([X, X_n])\n",
        "Y = pd.read_csv(path+\"data/recipe_train.csv\")['duration_label']"
      ],
      "id": "collectible-beverage",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6IbijM5I4H6",
        "outputId": "e5f4ba23-d328-4e76-d990-2f8bd32f23d1"
      },
      "source": [
        "vocab = pickle.load(open(path+\"data/countvec/train_steps_countvectorizer.pkl\", \"rb\"))\n",
        "vocab_dict = vocab.vocabulary_"
      ],
      "id": "-6IbijM5I4H6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX-kFS29IrSV"
      },
      "source": [
        "three = pd.read_csv(path+\"data/three.csv\")['steps']\n",
        "three_n = pd.read_csv(path+\"data/three.csv\").loc[:, ['n_steps', 'n_ingredients']]"
      ],
      "id": "pX-kFS29IrSV",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B04Id5i5JOC8"
      },
      "source": [
        "vectorizer = CountVectorizer(vocabulary=vocab_dict)\n",
        "three = vectorizer.transform(three)\n",
        "\n",
        "del vocab,  vocab_dict, vectorizer"
      ],
      "id": "B04Id5i5JOC8",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZx3P-fufjE6"
      },
      "source": [
        "three = three.toarray().astype(np.int32)\n",
        "three = np.hstack([three, three_n.values])"
      ],
      "id": "jZx3P-fufjE6",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pirHTOqygQKx"
      },
      "source": [
        "del three_n, X_n"
      ],
      "id": "pirHTOqygQKx",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i_PjB6s1-MX"
      },
      "source": [
        "X = np.vstack((X, three)).astype(np.int32)\n",
        "Y = np.hstack((Y, np.array([3.0 for i in range(three.shape[0])])))"
      ],
      "id": "8i_PjB6s1-MX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ambient-stevens"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X, X_t, y, y_t = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "del three"
      ],
      "id": "ambient-stevens",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "artistic-cowboy"
      },
      "source": [
        "# ------------------------------------------------------"
      ],
      "id": "artistic-cowboy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "civic-vienna",
        "outputId": "42d1df88-85aa-4243-818a-342bec34f578"
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "\n",
        "if 1:\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "id": "civic-vienna",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda:0 device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOcSZI962XJq"
      },
      "source": [
        "# 2 inputs"
      ],
      "id": "QOcSZI962XJq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgwI4oLR2WAL"
      },
      "source": [
        "X = torch.tensor(X)\n",
        "X_t = torch.tensor(X_t)"
      ],
      "id": "OgwI4oLR2WAL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RMUmbeL5qkQ",
        "outputId": "b650f9df-c36e-4df8-c984-a2e3d78462b9"
      },
      "source": [
        "y = torch.tensor(y)-1\n",
        "y_t = torch.tensor(y_t)-1\n",
        "\n",
        "l1 = X.shape[1]\n",
        "\n",
        "print(l1)"
      ],
      "id": "6RMUmbeL5qkQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPJR8qLz2r3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a278ecfc-9be1-417d-a151-68446a76a9ec"
      },
      "source": [
        "training_data = TensorDataset(X, y)\n",
        "testing_data = TensorDataset(X_t, y_t)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=32, shuffle=True)\n",
        "\n",
        "tf1,train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {tf1.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "id": "YPJR8qLz2r3r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([32, 17967])\n",
            "Labels batch shape: torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0hbD51X2wcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86aa5d15-ac51-4cf4-8b2e-bfb50378474f"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, l1):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "      \n",
        "        self.blackbox = nn.Sequential(\n",
        "            nn.Linear(l1, 2000),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.6),\n",
        "\n",
        "            nn.Linear(2000, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.8),\n",
        "\n",
        "            nn.Linear(200, 3),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blackbox(x)\n",
        "        return x\n",
        "\n",
        "model = NeuralNetwork(l1).to(device)\n",
        "print(model)"
      ],
      "id": "u0hbD51X2wcC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (blackbox): Sequential(\n",
            "    (0): Linear(in_features=17967, out_features=8000, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.6, inplace=False)\n",
            "    (3): Linear(in_features=8000, out_features=4000, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.8, inplace=False)\n",
            "    (6): Linear(in_features=4000, out_features=3, bias=True)\n",
            "    (7): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYnX_eiG4NeL"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    loss_ls = []\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        # Compute prediction error\n",
        "        pred = model(X.float())\n",
        "        loss = loss_fn(pred, y.long())\n",
        "        \n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(y)\n",
        "            loss_ls.append(loss)\n",
        "            \n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    print(f\"Avg train loss :{sum(loss_ls)/len(loss_ls)}\")\n",
        "\n",
        "def test(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X.float())\n",
        "            test_loss += loss_fn(pred, y.long()).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg test loss: {test_loss:>8f} \\n\")"
      ],
      "id": "mYnX_eiG4NeL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaALcs9o4dHC"
      },
      "source": [
        "# empty cuda memory\n",
        "if 1:\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    t = 1\n",
        "    lr = 1e-5"
      ],
      "id": "oaALcs9o4dHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUqCH7V2efeN"
      },
      "source": [
        "lr=8e-6"
      ],
      "id": "ZUqCH7V2efeN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjtdki894WFR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e078ad0d-8ae0-4f2e-c966-181d2d6137cb"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.008, amsgrad=False)\n",
        "epochs = 200\n",
        "\n",
        "while t < epochs:\n",
        "    print(f\"Epoch {t}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model)\n",
        "    \n",
        "    if t%5 == 0:\n",
        "        \n",
        "        lr = lr * 0.99\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.008, amsgrad=False)\n",
        "        print(f\"Learning rate adjusted to {lr}\")\n",
        "        \n",
        "        torch.save(model.state_dict(), path+f\"nn/model_{t}.pt\")\n",
        "        print(f\"Model saved to nn/model_{t}.pt\")\n",
        "    \n",
        "    t += 1\n",
        "\n",
        "print(\"Done!\")"
      ],
      "id": "zjtdki894WFR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.761930  [    0/43162]\n",
            "loss: 0.703474  [ 3200/43162]\n",
            "loss: 0.741789  [ 6400/43162]\n",
            "loss: 0.736764  [ 9600/43162]\n",
            "loss: 0.664158  [12800/43162]\n",
            "loss: 0.677017  [16000/43162]\n",
            "loss: 0.714896  [19200/43162]\n",
            "loss: 0.725014  [22400/43162]\n",
            "loss: 0.781269  [25600/43162]\n",
            "loss: 0.665006  [28800/43162]\n",
            "loss: 0.748388  [32000/43162]\n",
            "loss: 0.809015  [35200/43162]\n",
            "loss: 0.734407  [38400/43162]\n",
            "loss: 0.701991  [41600/43162]\n",
            "Avg train loss :0.7260797960417611\n",
            "Test Error: \n",
            " Accuracy: 80.4%, Avg test loss: 0.023221 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.671219  [    0/43162]\n",
            "loss: 0.715719  [ 3200/43162]\n",
            "loss: 0.781397  [ 6400/43162]\n",
            "loss: 0.701083  [ 9600/43162]\n",
            "loss: 0.809983  [12800/43162]\n",
            "loss: 0.795919  [16000/43162]\n",
            "loss: 0.669350  [19200/43162]\n",
            "loss: 0.812744  [22400/43162]\n",
            "loss: 0.709863  [25600/43162]\n",
            "loss: 0.649076  [28800/43162]\n",
            "loss: 0.747459  [32000/43162]\n",
            "loss: 0.663430  [35200/43162]\n",
            "loss: 0.697412  [38400/43162]\n",
            "loss: 0.681264  [41600/43162]\n",
            "Avg train loss :0.721851429768971\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg test loss: 0.023244 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.731386  [    0/43162]\n",
            "loss: 0.770321  [ 3200/43162]\n",
            "loss: 0.681516  [ 6400/43162]\n",
            "loss: 0.747033  [ 9600/43162]\n",
            "loss: 0.838608  [12800/43162]\n",
            "loss: 0.735381  [16000/43162]\n",
            "loss: 0.680770  [19200/43162]\n",
            "loss: 0.673184  [22400/43162]\n",
            "loss: 0.706266  [25600/43162]\n",
            "loss: 0.700438  [28800/43162]\n",
            "loss: 0.691371  [32000/43162]\n",
            "loss: 0.696101  [35200/43162]\n",
            "loss: 0.608085  [38400/43162]\n",
            "loss: 0.721022  [41600/43162]\n",
            "Avg train loss :0.7129629850387573\n",
            "Test Error: \n",
            " Accuracy: 80.3%, Avg test loss: 0.023235 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.747581  [    0/43162]\n",
            "loss: 0.652915  [ 3200/43162]\n",
            "loss: 0.709949  [ 6400/43162]\n",
            "loss: 0.734868  [ 9600/43162]\n",
            "loss: 0.666972  [12800/43162]\n",
            "loss: 0.711389  [16000/43162]\n",
            "loss: 0.680398  [19200/43162]\n",
            "loss: 0.654670  [22400/43162]\n",
            "loss: 0.670941  [25600/43162]\n",
            "loss: 0.719972  [28800/43162]\n",
            "loss: 0.710055  [32000/43162]\n",
            "loss: 0.642443  [35200/43162]\n",
            "loss: 0.666685  [38400/43162]\n",
            "loss: 0.687879  [41600/43162]\n",
            "Avg train loss :0.68976548739842\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg test loss: 0.023260 \n",
            "\n",
            "Learning rate adjusted to 7.8408e-06\n",
            "Model saved to nn/model_10.pt\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.671627  [    0/43162]\n",
            "loss: 0.739230  [ 3200/43162]\n",
            "loss: 0.636434  [ 6400/43162]\n",
            "loss: 0.722520  [ 9600/43162]\n",
            "loss: 0.660552  [12800/43162]\n",
            "loss: 0.640639  [16000/43162]\n",
            "loss: 0.647853  [19200/43162]\n",
            "loss: 0.789656  [22400/43162]\n",
            "loss: 0.645276  [25600/43162]\n",
            "loss: 0.618653  [28800/43162]\n",
            "loss: 0.731583  [32000/43162]\n",
            "loss: 0.734651  [35200/43162]\n",
            "loss: 0.696700  [38400/43162]\n",
            "loss: 0.644198  [41600/43162]\n",
            "Avg train loss :0.6842551699706486\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg test loss: 0.023226 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.672267  [    0/43162]\n",
            "loss: 0.612038  [ 3200/43162]\n",
            "loss: 0.636414  [ 6400/43162]\n",
            "loss: 0.728422  [ 9600/43162]\n",
            "loss: 0.651621  [12800/43162]\n",
            "loss: 0.672302  [16000/43162]\n",
            "loss: 0.622644  [19200/43162]\n",
            "loss: 0.689954  [22400/43162]\n",
            "loss: 0.653600  [25600/43162]\n",
            "loss: 0.640923  [28800/43162]\n",
            "loss: 0.688954  [32000/43162]\n",
            "loss: 0.654217  [35200/43162]\n",
            "loss: 0.632343  [38400/43162]\n",
            "loss: 0.648856  [41600/43162]\n",
            "Avg train loss :0.6574682423046657\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg test loss: 0.023235 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.657903  [    0/43162]\n",
            "loss: 0.746927  [ 3200/43162]\n",
            "loss: 0.673874  [ 6400/43162]\n",
            "loss: 0.666650  [ 9600/43162]\n",
            "loss: 0.624321  [12800/43162]\n",
            "loss: 0.605746  [16000/43162]\n",
            "loss: 0.707630  [19200/43162]\n",
            "loss: 0.748724  [22400/43162]\n",
            "loss: 0.685047  [25600/43162]\n",
            "loss: 0.706395  [28800/43162]\n",
            "loss: 0.670455  [32000/43162]\n",
            "loss: 0.670642  [35200/43162]\n",
            "loss: 0.636945  [38400/43162]\n",
            "loss: 0.636784  [41600/43162]\n",
            "Avg train loss :0.6741459327084678\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg test loss: 0.023291 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.609171  [    0/43162]\n",
            "loss: 0.583196  [ 3200/43162]\n",
            "loss: 0.689426  [ 6400/43162]\n",
            "loss: 0.645724  [ 9600/43162]\n",
            "loss: 0.751354  [12800/43162]\n",
            "loss: 0.630822  [16000/43162]\n",
            "loss: 0.735575  [19200/43162]\n",
            "loss: 0.647683  [22400/43162]\n",
            "loss: 0.640780  [25600/43162]\n",
            "loss: 0.640339  [28800/43162]\n",
            "loss: 0.730679  [32000/43162]\n",
            "loss: 0.638782  [35200/43162]\n",
            "loss: 0.628218  [38400/43162]\n",
            "loss: 0.609167  [41600/43162]\n",
            "Avg train loss :0.6557797108377729\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg test loss: 0.023290 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.688692  [    0/43162]\n",
            "loss: 0.608075  [ 3200/43162]\n",
            "loss: 0.649681  [ 6400/43162]\n",
            "loss: 0.693838  [ 9600/43162]\n",
            "loss: 0.647084  [12800/43162]\n",
            "loss: 0.657088  [16000/43162]\n",
            "loss: 0.653627  [19200/43162]\n",
            "loss: 0.739931  [22400/43162]\n",
            "loss: 0.586336  [25600/43162]\n",
            "loss: 0.676741  [28800/43162]\n",
            "loss: 0.677600  [32000/43162]\n",
            "loss: 0.626153  [35200/43162]\n",
            "loss: 0.609326  [38400/43162]\n",
            "loss: 0.681579  [41600/43162]\n",
            "Avg train loss :0.6568393536976406\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg test loss: 0.023274 \n",
            "\n",
            "Learning rate adjusted to 7.762392e-06\n",
            "Model saved to nn/model_15.pt\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.611158  [    0/43162]\n",
            "loss: 0.661282  [ 3200/43162]\n",
            "loss: 0.650160  [ 6400/43162]\n",
            "loss: 0.617590  [ 9600/43162]\n",
            "loss: 0.716984  [12800/43162]\n",
            "loss: 0.637261  [16000/43162]\n",
            "loss: 0.703376  [19200/43162]\n",
            "loss: 0.620684  [22400/43162]\n",
            "loss: 0.736068  [25600/43162]\n",
            "loss: 0.615847  [28800/43162]\n",
            "loss: 0.626311  [32000/43162]\n",
            "loss: 0.669158  [35200/43162]\n",
            "loss: 0.645857  [38400/43162]\n",
            "loss: 0.657986  [41600/43162]\n",
            "Avg train loss :0.6549801571028573\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg test loss: 0.023300 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.563860  [    0/43162]\n",
            "loss: 0.662506  [ 3200/43162]\n",
            "loss: 0.696390  [ 6400/43162]\n",
            "loss: 0.672376  [ 9600/43162]\n",
            "loss: 0.622174  [12800/43162]\n",
            "loss: 0.664270  [16000/43162]\n",
            "loss: 0.662608  [19200/43162]\n",
            "loss: 0.716186  [22400/43162]\n",
            "loss: 0.648547  [25600/43162]\n",
            "loss: 0.617860  [28800/43162]\n",
            "loss: 0.674510  [32000/43162]\n",
            "loss: 0.577055  [35200/43162]\n",
            "loss: 0.724437  [38400/43162]\n",
            "loss: 0.664689  [41600/43162]\n",
            "Avg train loss :0.6548190414905548\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg test loss: 0.023340 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.623377  [    0/43162]\n",
            "loss: 0.654420  [ 3200/43162]\n",
            "loss: 0.718071  [ 6400/43162]\n",
            "loss: 0.652093  [ 9600/43162]\n",
            "loss: 0.641101  [12800/43162]\n",
            "loss: 0.586282  [16000/43162]\n",
            "loss: 0.628483  [19200/43162]\n",
            "loss: 0.625813  [22400/43162]\n",
            "loss: 0.646797  [25600/43162]\n",
            "loss: 0.649354  [28800/43162]\n",
            "loss: 0.649186  [32000/43162]\n",
            "loss: 0.653713  [35200/43162]\n",
            "loss: 0.565119  [38400/43162]\n",
            "loss: 0.612714  [41600/43162]\n",
            "Avg train loss :0.6361801964896066\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg test loss: 0.023364 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.602140  [    0/43162]\n",
            "loss: 0.610352  [ 3200/43162]\n",
            "loss: 0.587943  [ 6400/43162]\n",
            "loss: 0.669158  [ 9600/43162]\n",
            "loss: 0.602020  [12800/43162]\n",
            "loss: 0.626040  [16000/43162]\n",
            "loss: 0.561613  [19200/43162]\n",
            "loss: 0.592086  [22400/43162]\n",
            "loss: 0.621573  [25600/43162]\n",
            "loss: 0.601707  [28800/43162]\n",
            "loss: 0.618002  [32000/43162]\n",
            "loss: 0.595798  [35200/43162]\n",
            "loss: 0.599953  [38400/43162]\n",
            "loss: 0.641773  [41600/43162]\n",
            "Avg train loss :0.6092969690050397\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg test loss: 0.023371 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.618566  [    0/43162]\n",
            "loss: 0.659543  [ 3200/43162]\n",
            "loss: 0.702896  [ 6400/43162]\n",
            "loss: 0.654193  [ 9600/43162]\n",
            "loss: 0.624722  [12800/43162]\n",
            "loss: 0.608754  [16000/43162]\n",
            "loss: 0.638828  [19200/43162]\n",
            "loss: 0.615752  [22400/43162]\n",
            "loss: 0.633252  [25600/43162]\n",
            "loss: 0.669962  [28800/43162]\n",
            "loss: 0.645597  [32000/43162]\n",
            "loss: 0.637017  [35200/43162]\n",
            "loss: 0.619029  [38400/43162]\n",
            "loss: 0.733375  [41600/43162]\n",
            "Avg train loss :0.6472490472452981\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg test loss: 0.023372 \n",
            "\n",
            "Learning rate adjusted to 7.68476808e-06\n",
            "Model saved to nn/model_20.pt\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.594421  [    0/43162]\n",
            "loss: 0.673280  [ 3200/43162]\n",
            "loss: 0.558285  [ 6400/43162]\n",
            "loss: 0.585515  [ 9600/43162]\n",
            "loss: 0.707624  [12800/43162]\n",
            "loss: 0.615740  [16000/43162]\n",
            "loss: 0.698294  [19200/43162]\n",
            "loss: 0.622589  [22400/43162]\n",
            "loss: 0.649717  [25600/43162]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7221bdcc13b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-6aad1a1b6ff5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Compute prediction error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EyGensl4cZs"
      },
      "source": [
        "X_test = scipy.sparse.load_npz(path+'data/countvec/test_steps_vec.npz').toarray().astype(np.float32)"
      ],
      "id": "-EyGensl4cZs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhBTv9948v2c"
      },
      "source": [
        "X_test = torch.tensor(X_test)"
      ],
      "id": "uhBTv9948v2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWNsme-M8UrQ"
      },
      "source": [
        "testing_data = TensorDataset(X_t)\n",
        "\n",
        "test_dataloader = DataLoader(testing_data, batch_size=64, shuffle=True)"
      ],
      "id": "XWNsme-M8UrQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "valuable-pearl"
      },
      "source": [
        "test_dataloader = DataLoader(testing_data, batch_size=64, shuffle=False)\n",
        "pre = []\n",
        "with torch.no_grad():\n",
        "  for X0 in test_dataloader:\n",
        "    X0 = X0[0]\n",
        "    X0 = X0.to(device)\n",
        "    pred = model(X0)\n",
        "    pre.append(pred.argmax(1))"
      ],
      "id": "valuable-pearl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sLY_WSTLbBx"
      },
      "source": [
        "pre = torch.cat([i for i in pre])"
      ],
      "id": "3sLY_WSTLbBx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH7rwKPONbTB"
      },
      "source": [
        "pre = pre.cpu().numpy()+1"
      ],
      "id": "bH7rwKPONbTB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Om-UrJ--7c"
      },
      "source": [
        "pre = pre.astype('float')"
      ],
      "id": "18Om-UrJ--7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpVJil8eAD03",
        "outputId": "98b5141e-f2cf-4326-a944-c5a5be1b8f74"
      },
      "source": [
        "pre"
      ],
      "id": "XpVJil8eAD03",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 3., 1., ..., 2., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MDS6ZZuP-4W"
      },
      "source": [
        "y_test = np.array(y_t)+1"
      ],
      "id": "0MDS6ZZuP-4W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaTy0Tpo-1HM"
      },
      "source": [
        "pred = pd.DataFrame(pre, index=range(1,10001), columns=['duration_label'])"
      ],
      "id": "zaTy0Tpo-1HM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWNCQoxDAlq8"
      },
      "source": [
        "pred.to_csv(\"pred.csv\", header=True, index=True)"
      ],
      "id": "YWNCQoxDAlq8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY9BOR6AMCTw",
        "outputId": "38b733f7-7d29-4126-a4d1-32a0f6570d21"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "print(f\"accu: {accuracy_score(y_test, pre)}\")\n",
        "\n",
        "precision = precision_score(y_test, pre, average=None, zero_division=0)\n",
        "recall = recall_score(y_test, pre, average=None, zero_division=0)\n",
        "f1 = f1_score(y_test, pre, average=None, zero_division=0)\n",
        "score = pd.DataFrame({'Precision':precision, \"Recall\":recall, \"F_score\":f1}, index=[1,2,3])\n",
        "print(score)\n",
        "matrix = confusion_matrix(y_test, pre)\n",
        "matrix = pd.DataFrame(matrix, index=[1,2,3], columns=[1,2,3])\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(matrix, end='\\n\\n')"
      ],
      "id": "aY9BOR6AMCTw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accu: 0.7970530998053934\n",
            "   Precision    Recall   F_score\n",
            "1   0.763746  0.755310  0.759504\n",
            "2   0.788554  0.760254  0.774145\n",
            "3   0.841791  0.891277  0.865827\n",
            "\n",
            "Confusion matrix:\n",
            "      1     2     3\n",
            "1  2667   616   248\n",
            "2   700  3114   282\n",
            "3   125   219  2820\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}